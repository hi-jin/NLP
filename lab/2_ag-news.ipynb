{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d3ddf8",
   "metadata": {},
   "source": [
    "# AG News Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a09c948",
   "metadata": {},
   "source": [
    "### classes\n",
    "- world\n",
    "- sports\n",
    "- business\n",
    "- science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f18993",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0ff451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pytorch_lightning import Trainer, LightningDataModule, LightningModule\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a300ee5",
   "metadata": {},
   "source": [
    "## arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e569f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    data_path = \"../dataset/ag-news\",\n",
    "    \n",
    "    lr = 0.0001,\n",
    "    max_epochs = 200,\n",
    "    batch_size = 128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ba7d2",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcbc6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape : (120000, 3)\n",
      "test_df.shape : (7600, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(args.data_path, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(args.data_path, \"test.csv\"))\n",
    "\n",
    "print(f\"train_df.shape : {train_df.shape}\")\n",
    "print(f\"test_df.shape : {test_df.shape}\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2cc967",
   "metadata": {},
   "source": [
    "### Title + Description와 Class Index로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a474ebf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0         Wall St. Bears Claw Back Into the Black (Reute...\n",
       " 1         Carlyle Looks Toward Commercial Aerospace (Reu...\n",
       " 2         Oil and Economy Cloud Stocks' Outlook (Reuters...\n",
       " 3         Iraq Halts Oil Exports from Main Southern Pipe...\n",
       " 4         Oil prices soar to all-time record, posing new...\n",
       "                                 ...                        \n",
       " 119995    Pakistan's Musharraf Says Won't Quit as Army C...\n",
       " 119996    Renteria signing a top-shelf deal Red Sox gene...\n",
       " 119997    Saban not going to Dolphins yet The Miami Dolp...\n",
       " 119998    Today's NFL games PITTSBURGH at NY GIANTS Time...\n",
       " 119999    Nets get Carter from Raptors INDIANAPOLIS -- A...\n",
       " Name: Title, Length: 120000, dtype: object,\n",
       " 0         3\n",
       " 1         3\n",
       " 2         3\n",
       " 3         3\n",
       " 4         3\n",
       "          ..\n",
       " 119995    1\n",
       " 119996    2\n",
       " 119997    2\n",
       " 119998    2\n",
       " 119999    2\n",
       " Name: Class Index, Length: 120000, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = train_df[\"Title\"].str.cat(train_df[\"Description\"], sep=\" \")\n",
    "train_labels = train_df[\"Class Index\"]\n",
    "\n",
    "test_sentences = test_df[\"Title\"].str.cat(test_df[\"Description\"], sep=\" \")\n",
    "test_labels = test_df[\"Class Index\"]\n",
    "\n",
    "train_sentences, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627be95f",
   "metadata": {},
   "source": [
    "## vocabulary 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543faf4a",
   "metadata": {},
   "source": [
    "- train data 사용\n",
    "- 공백 단위로 word 추출\n",
    "- 소문자만 이용 : lower()\n",
    "\n",
    "word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d9a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "\n",
    "for sentence in train_sentences:\n",
    "    for word in sentence.split():\n",
    "        word = word.lower()\n",
    "        vocabulary.add(word)\n",
    "\n",
    "vocabulary = sorted(list(vocabulary))\n",
    "\n",
    "word_to_id = {\"[PAD]\": 0, \"[UNK]\": 1}\n",
    "id_to_word = [\"[PAD]\", \"[UNK]\"]\n",
    "\n",
    "for word in vocabulary:\n",
    "    word_to_id[word] = len(word_to_id)\n",
    "    id_to_word.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46df4287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocabulary) : 158715\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(vocabulary) : {len(vocabulary)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc3e567",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f81218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, word_to_id: dict, sentences: pd.Series, labels: pd.Series=None):\n",
    "        super().__init__()\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.word_to_id = word_to_id\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sequence = []\n",
    "        sentence = self.sentences[index]\n",
    "        label = self.labels[index]\n",
    "        for word in sentence.split():\n",
    "            word = word.lower()\n",
    "            id = 1 if word not in self.word_to_id else self.word_to_id[word]\n",
    "            sequence.append(id)\n",
    "        \n",
    "        sequence = torch.tensor(sequence, dtype=torch.long)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return sequence, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029c417",
   "metadata": {},
   "source": [
    "## DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d76bdf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataModule(LightningDataModule):\n",
    "    def __init__(self, train_sentences, train_labels, test_sentences, test_labels, word_to_id, batch_size):\n",
    "        super().__init__()\n",
    "        self.train_sentences = train_sentences\n",
    "        self.train_labels = train_labels\n",
    "        self.test_sentences = test_sentences\n",
    "        self.test_labels = test_labels\n",
    "        self.word_to_id = word_to_id\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset, self.val_dataset = random_split(SequenceDataset(self.word_to_id, self.train_sentences, self.train_labels), [0.8, 0.2])\n",
    "        if stage == \"test\":\n",
    "            self.test_dataset = SequenceDataset(self.word_to_id, self.test_sentences, self.test_labels)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, self.batch_size, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, self.batch_size, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        sequences, labels = list(zip(*batch))\n",
    "        sequences = nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "        labels = torch.stack(labels)\n",
    "        \n",
    "        return [sequences, labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa3180",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a85507",
   "metadata": {},
   "source": [
    "### Embedding + FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cbb25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(LightningModule):\n",
    "    def __init__(self, n_vocab, lr):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(n_vocab, 1000)\n",
    "        self.fc1 = nn.Linear(1000, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 4)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x, _ = torch.max(x, dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y -= 1  # 1~4 => 0~3\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"training_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y -= 1\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = np.mean(list(map(int, torch.argmax(y_hat, dim=1)==y)))\n",
    "        metrics = {\"val_loss\": loss, \"val_acc\": acc}\n",
    "        self.log_dict(metrics)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y -= 1\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = np.mean(list(map(int, torch.argmax(y_hat, dim=1)==y)))\n",
    "        metrics = {\"test_loss\": loss, \"test_acc\": acc}\n",
    "        self.log_dict(metrics)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3da73",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0295a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "ag_news_data = SequenceDataModule(train_sentences, train_labels, test_sentences, test_labels, word_to_id, args.batch_size)\n",
    "model = SequenceModel(len(word_to_id), args.lr)\n",
    "trainer = Trainer(max_epochs=args.max_epochs, callbacks=[EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9dd02",
   "metadata": {},
   "source": [
    "### 초기 상태 25% 정확도 (클래스 4개 중 1개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf7dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/torch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d583a4637f42869821d676b547ef1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.24947368421052632\n",
      "        test_loss           1.4024487733840942\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.4024487733840942, 'test_acc': 0.24947368421052632}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, ag_news_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8227b6",
   "metadata": {},
   "source": [
    "### gpu 없이 학습하려니 너무 오래 걸려서 서버에서 학습하고 weigts만 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d62d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit(model, ag_news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8285cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b4cf92eadc42c58c54ffd7b727196f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8735526315789474\n",
      "        test_loss            0.404371052980423\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.404371052980423, 'test_acc': 0.8735526315789474}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequenceModel(len(word_to_id), args.lr)\n",
    "model.load_state_dict(torch.load(\"2_weights.pth\"))\n",
    "trainer.test(model, ag_news_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
